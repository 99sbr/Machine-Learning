{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing dataset..\n",
      "Importing completed !!\n",
      "Cleaning and parsing the training set tweets...\n",
      "\n",
      "Review 100 of 248\n",
      "\n",
      "Review 200 of 248\n",
      "\n",
      "Cleaning and parsing the test set tweets...\n",
      "\n",
      "Review 100 of 249\n",
      "\n",
      "Review 200 of 249\n",
      "\n",
      " Acoording to training set tweets the person is Balanced being and Trustable and Optimist also. \n",
      "\n",
      "Training the random forest....\n",
      " Acoording to test set tweets the person is Balanced being and and Trustable and Optimist also. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('importing dataset..')\n",
    "frame=pd.read_csv('train.csv',delimiter=',')\n",
    "print('Importing completed !!')\n",
    "cols=['polarity','ID','date','query','user','tweet']\n",
    "frame.columns=cols\n",
    "del frame['ID']\n",
    "del frame['date']\n",
    "del frame['user']\n",
    "polarity=frame.polarity\n",
    "tweet=frame.tweet\n",
    "X_train, X_test, y_train, y_test = train_test_split(tweet, polarity, test_size=0.5)\n",
    "# try test_size=0.5 ,0.25 and 0.33\n",
    "def tweet_to_words(raw_review):\n",
    "        ex=raw_review\n",
    "        # now we import BeautifulSoup to remove the tags and markups from the text data \n",
    "        soup=BeautifulSoup(ex)\n",
    "        clean_text=soup.get_text()\n",
    "        # Dealing with Punctuations\n",
    "        # Use regular expressions to do a find-and-replace\n",
    "        letters_only=re.sub(\"[^a-zA-Z]\", \" \", clean_text)\n",
    "        # tokenizing\n",
    "        lower_case=letters_only.lower()\n",
    "        words=lower_case.split()\n",
    "        # remove stopwords\n",
    "        stops=set(stopwords.words('english'))\n",
    "        words= [w for w in words if not w in stops]\n",
    "        #Stemming\n",
    "        lancaster_stemmer=LancasterStemmer()\n",
    "        stem_word=[]\n",
    "        for word in words:\n",
    "            stem_word.append(lancaster_stemmer.stem(word))\n",
    "            new_set=\" \".join( stem_word )\n",
    "        return new_set\n",
    "    \n",
    "num_reviews = X_train.size\n",
    "print \"Cleaning and parsing the training set tweets...\\n\"\n",
    "clean_train_tweets = []\n",
    "X_train=X_train.tolist()\n",
    "for i in range(num_reviews ):\n",
    "    # If the index is evenly divisible by 100, print a message\n",
    "    if( (i+1)%100 == 0 ):\n",
    "        print \"Review %d of %d\\n\" % ( i+1, num_reviews )                                                                    \n",
    "    clean_train_tweets.append( tweet_to_words( X_train[i] ))\n",
    " \n",
    "\n",
    "num_reviews2=X_test.size\n",
    "print \"Cleaning and parsing the test set tweets...\\n\"\n",
    "clean_test_tweets = []\n",
    "X_test=X_test.tolist()\n",
    "for i in range(num_reviews2 ):\n",
    "    # If the index is evenly divisible by 100, print a message\n",
    "    if( (i+1)%100 == 0 ):\n",
    "        print \"Review %d of %d\\n\" % ( i+1, num_reviews2 )                                                                    \n",
    "    clean_test_tweets.append( tweet_to_words( X_test[i] ))\n",
    "# this function calculates the probability of a person belonging to a particular personality on the basis of polarity of his tweets\n",
    "def personality_predictor(polarity):\n",
    "    polarity=list(polarity)\n",
    "    a=len(polarity)\n",
    "    pos_count=polarity.count(4)\n",
    "    neutral_count=polarity.count(2)\n",
    "    neg_count=polarity.count(0)\n",
    "    personality=[]\n",
    "    if ((pos_count/a)>0.5):\n",
    "        personality.append('Enthusiastic and')\n",
    "    elif ((neg_count/a)>0.5):\n",
    "        personality.append('Apathetic and ')\n",
    "    elif (neutral_count/a>0.5):\n",
    "        personality.append('Pretty Calm and ')\n",
    "    else:\n",
    "        personality.append('Balanced being and')\n",
    "    \n",
    "    if ((pos_count+neutral_count)>0.5):\n",
    "        personality.append('Trustable and Optimist')\n",
    "    \n",
    "    elif ((pos_count+neutral_count)<0.5):\n",
    "            personality.append('Judgemental,Harsh')\n",
    "    else:\n",
    "            personality.append('Pessimistic')\n",
    "            \n",
    "    return personality\n",
    "   \n",
    "result=personality_predictor(y_test)\n",
    "print (' Acoording to training set tweets the person is %s %s also. \\n') % (result[0],result[1])\n",
    "#feature Creation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#CountVectorizer: Scikit learn's bag of tool\n",
    "vectorizer=CountVectorizer(analyzer='word', tokenizer=None,preprocessor=None,stop_words=None,max_features=500)\n",
    "train_data_features=vectorizer.fit_transform(clean_train_tweets)\n",
    "train_data_features= train_data_features.toarray()\n",
    "# Random Forest\n",
    "print \"Training the random forest....\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest=RandomForestClassifier(n_estimators=100)\n",
    "forest=forest.fit(train_data_features,y_train)\n",
    "# Use the random forest to make sentiment label predictions\n",
    "test_data_features=vectorizer.fit_transform(clean_test_tweets)\n",
    "test_data_features= test_data_features.toarray()\n",
    "result2 = forest.predict(test_data_features)\n",
    "result3=personality_predictor(result2)\n",
    "print (' Acoording to test set tweets the person is %s and %s also. \\n') % (result3[0],result3[1])\n",
    "\n",
    "# The slices will be ordered and plotted counter-clockwise.\n",
    "labels = 'Positive Tweets', 'Neutral Tweets', 'Negative Tweets'\n",
    "y_train=list(y_train)\n",
    "train_pos=y_train.count(4)\n",
    "train_neu=y_train.count(2)\n",
    "train_neg=y_train.count(0)\n",
    "train_sizes = [train_pos,train_neu, train_neg]\n",
    "\n",
    "y_test=list(y_test)\n",
    "test_pos=y_test.count(4)\n",
    "test_neu=y_test.count(2)\n",
    "test_neg=y_test.count(0)\n",
    "test_sizes = [test_pos,test_neu, test_neg]\n",
    "\n",
    "result2=list(result2)\n",
    "pred_pos=result2.count(4)\n",
    "pred_neu=result2.count(2)\n",
    "pred_neg=result2.count(0)\n",
    "pred_sizes = [pred_pos,pred_neu,pred_neg]\n",
    "colors = ['yellowgreen', 'gold', 'lightskyblue']\n",
    "explode = (0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "# Set aspect ratio to be equal so that pie is drawn as a circle.\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "import numpy as np\n",
    "ax.pie(train_sizes, explode=explode, labels=labels, colors=colors,\n",
    "       autopct='%1.1f%%', shadow=True, startangle=90,\n",
    "       radius=0.25, center=(0, 0), frame=True)\n",
    "ax.pie(test_sizes, explode=explode, labels=labels, colors=colors,\n",
    "       autopct='%1.1f%%', shadow=True, startangle=90,\n",
    "       radius=0.25, center=(1, 1), frame=True)\n",
    "ax.pie(pred_sizes, explode=explode, labels=labels, colors=colors,\n",
    "       autopct='%1.1f%%', shadow=True, startangle=90,\n",
    "       radius=0.25, center=(0, 1), frame=True)\n",
    "\n",
    "# Set aspect ratio to be equal so that pie is drawn as a circle.\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_xticklabels([\"Predicted Tweets\", \"\"])\n",
    "ax.set_yticklabels([\"\", \"Training set tweets\"])\n",
    "ax.set_xlim((-0.5, 1.5))\n",
    "ax.set_ylim((-0.5, 1.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
