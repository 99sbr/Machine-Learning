{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set movie reviews...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subir\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\bs4\\__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 25000\n",
      "\n",
      "Review 2000 of 25000\n",
      "\n",
      "Review 3000 of 25000\n",
      "\n",
      "Review 4000 of 25000\n",
      "\n",
      "Review 5000 of 25000\n",
      "\n",
      "Review 6000 of 25000\n",
      "\n",
      "Review 7000 of 25000\n",
      "\n",
      "Review 8000 of 25000\n",
      "\n",
      "Review 9000 of 25000\n",
      "\n",
      "Review 10000 of 25000\n",
      "\n",
      "Review 11000 of 25000\n",
      "\n",
      "Review 12000 of 25000\n",
      "\n",
      "Review 13000 of 25000\n",
      "\n",
      "Review 14000 of 25000\n",
      "\n",
      "Review 15000 of 25000\n",
      "\n",
      "Review 16000 of 25000\n",
      "\n",
      "Review 17000 of 25000\n",
      "\n",
      "Review 18000 of 25000\n",
      "\n",
      "Review 19000 of 25000\n",
      "\n",
      "Review 20000 of 25000\n",
      "\n",
      "Review 21000 of 25000\n",
      "\n",
      "Review 22000 of 25000\n",
      "\n",
      "Review 23000 of 25000\n",
      "\n",
      "Review 24000 of 25000\n",
      "\n",
      "Review 25000 of 25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"labeledTrainData.tsv\", header=0,delimiter=\"\\t\", quoting=3)\n",
    "\n",
    "\n",
    "def review_to_words(raw_review):\n",
    "        ex=raw_review\n",
    "        # now we import BeautifulSoup to remove the tags and markups from the text data\n",
    "        from bs4 import BeautifulSoup\n",
    "        soup=BeautifulSoup(ex)\n",
    "        clean_text=soup.get_text()\n",
    "        # Dealing with Punctuations\n",
    "        import re\n",
    "        # Use regular expressions to do a find-and-replace\n",
    "        letters_only=re.sub(\"[^a-zA-Z]\", \" \", clean_text)\n",
    "        # tokenization\n",
    "        lower_case=letters_only.lower()\n",
    "        words=lower_case.split()\n",
    "\n",
    "        # remove stopword\n",
    "        import nltk\n",
    "        from nltk.corpus import stopwords\n",
    "        stops=set(stopwords.words('english'))\n",
    "        words= [w for w in words if not w in stops]\n",
    "\n",
    "\n",
    "        # Stemming\n",
    "        from nltk.stem.lancaster import LancasterStemmer\n",
    "        lancaster_stemmer=LancasterStemmer()\n",
    "        stem_word=[]\n",
    "        for word in words:\n",
    "            stem_word.append(lancaster_stemmer.stem(word))\n",
    "            new_set=\" \".join( stem_word )\n",
    "        return new_set\n",
    "    \n",
    "    \n",
    "\n",
    "num_reviews = train[\"review\"].size\n",
    "print \"Cleaning and parsing the training set movie reviews...\\n\"\n",
    "clean_train_reviews = []\n",
    "for i in xrange( 0, num_reviews ):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print \"Review %d of %d\\n\" % ( i+1, num_reviews )                                                                    \n",
    "    clean_train_reviews.append( review_to_words( train[\"review\"][i] ))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating the bag of words... (-: \n",
      "\n",
      "(25000L, 5000L)\n",
      "Training the random forest....\n",
      "(25000, 2)\n",
      " cleaning and passing the test set movie reviews.....\n",
      "\n",
      "Review 1 out of 25000\n",
      "\n",
      "Review 1001 out of 25000\n",
      "\n",
      "Review 2001 out of 25000\n",
      "\n",
      "Review 3001 out of 25000\n",
      "\n",
      "Review 4001 out of 25000\n",
      "\n",
      "Review 5001 out of 25000\n",
      "\n",
      "Review 6001 out of 25000\n",
      "\n",
      "Review 7001 out of 25000\n",
      "\n",
      "Review 8001 out of 25000\n",
      "\n",
      "Review 9001 out of 25000\n",
      "\n",
      "Review 10001 out of 25000\n",
      "\n",
      "Review 11001 out of 25000\n",
      "\n",
      "Review 12001 out of 25000\n",
      "\n",
      "Review 13001 out of 25000\n",
      "\n",
      "Review 14001 out of 25000\n",
      "\n",
      "Review 15001 out of 25000\n",
      "\n",
      "Review 16001 out of 25000\n",
      "\n",
      "Review 17001 out of 25000\n",
      "\n",
      "Review 18001 out of 25000\n",
      "\n",
      "Review 19001 out of 25000\n",
      "\n",
      "Review 20001 out of 25000\n",
      "\n",
      "Review 21001 out of 25000\n",
      "\n",
      "Review 22001 out of 25000\n",
      "\n",
      "Review 23001 out of 25000\n",
      "\n",
      "Review 24001 out of 25000\n",
      "\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print \"creating the bag of words... (-: \\n\"\n",
    "\n",
    "#feature Creation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#CountVectorizer: Scikit learn's bag of tool\n",
    "vectorizer=CountVectorizer(analyzer='word', tokenizer=None,preprocessor=None,stop_words=None,max_features=5000)\n",
    "train_data_features=vectorizer.fit_transform(clean_train_reviews)\n",
    "train_data_features= train_data_features.toarray()\n",
    "print train_data_features.shape\n",
    "# Take a look at the words in the vocabulary\n",
    "vocab = vectorizer.get_feature_names()\n",
    "# Random Forest\n",
    "print \"Training the random forest....\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest=RandomForestClassifier(n_estimators=100)\n",
    "forest=forest.fit(train_data_features,train['sentiment'])\n",
    "\n",
    "#Reading the test data\n",
    "test=pd.read_csv(\"testData.tsv\", header=0,delimiter='\\t',quoting=3)\n",
    "# quoting 3 tells pythom to ignore \" \"\n",
    "#header 0 says first line contains header\n",
    "print test.shape\n",
    "num_reviews=len(test['review'])\n",
    "clean_test_reviews=[]\n",
    "print \" cleaning and passing the test set movie reviews.....\\n\"\n",
    "for i in xrange(0,num_reviews):\n",
    "    if (i+1)%1000 == 1:\n",
    "        print \"Review %d out of %d\\n\" % (i+1,num_reviews)\n",
    "    clean_review=review_to_words(test['review'][i])\n",
    "    clean_test_reviews.append(clean_review)\n",
    "    \n",
    "test_data_features=vectorizer.fit_transform(clean_test_reviews)\n",
    "test_data_features= test_data_features.toarray()\n",
    "print test_data_features\n",
    "# Use the random forest to make sentiment label predictions\n",
    "result = forest.predict(test_data_features)\n",
    "# Copy the results to a pandas dataframe with an \"id\" column and\n",
    "# a \"sentiment\" column\n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
    "\n",
    "# Use pandas to write the comma-separated output file\n",
    "output.to_csv( \"Bag_of_Words_model.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
